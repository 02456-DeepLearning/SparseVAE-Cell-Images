Mon Nov 28 11:12:04 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-PCIE...  On   | 00000000:58:00.0 Off |                    0 |
| N/A   28C    P0    25W / 250W |      0MiB / 32768MiB |      0%   E. Process |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
VAE Baseline Experiments

Using cuda device...
Loading cell dataset...
Done!

Training VAE model from scratch...
Training VAE model...
Train Epoch: 1 [0/70668 (0%)]	Loss: 9709.647461
Train Epoch: 1 [3200/70668 (5%)]	Loss: 8920.777344
Train Epoch: 1 [6400/70668 (9%)]	Loss: 8544.182617
Train Epoch: 1 [9600/70668 (14%)]	Loss: 8861.381836
Train Epoch: 1 [12800/70668 (18%)]	Loss: 8516.085938
Train Epoch: 1 [16000/70668 (23%)]	Loss: 8769.190430
Train Epoch: 1 [19200/70668 (27%)]	Loss: 8680.275391
Train Epoch: 1 [22400/70668 (32%)]	Loss: 8497.104492
Train Epoch: 1 [25600/70668 (36%)]	Loss: 8502.063477
Train Epoch: 1 [28800/70668 (41%)]	Loss: 8429.372070
Train Epoch: 1 [32000/70668 (45%)]	Loss: 8341.394531
Train Epoch: 1 [35200/70668 (50%)]	Loss: 8620.557617
Train Epoch: 1 [38400/70668 (54%)]	Loss: 8133.534668
Train Epoch: 1 [41600/70668 (59%)]	Loss: 8457.206055
Train Epoch: 1 [44800/70668 (63%)]	Loss: 8422.642578
Train Epoch: 1 [48000/70668 (68%)]	Loss: 8243.313477
Train Epoch: 1 [51200/70668 (72%)]	Loss: 8174.950195
Train Epoch: 1 [54400/70668 (77%)]	Loss: 8372.678711
Train Epoch: 1 [57600/70668 (81%)]	Loss: 8403.019531
Train Epoch: 1 [60800/70668 (86%)]	Loss: 8366.862305
Train Epoch: 1 [64000/70668 (91%)]	Loss: 8314.338867
Train Epoch: 1 [67200/70668 (95%)]	Loss: 8482.789062
Train Epoch: 1 [70400/70668 (100%)]	Loss: 8347.351562
====> Epoch: 1 Average loss: 8495.5501
====> Test set loss: 8389.4117 - VLB-VAE : 268385.2178
Train Epoch: 2 [0/70668 (0%)]	Loss: 8381.759766
Train Epoch: 2 [3200/70668 (5%)]	Loss: 8489.688477
Train Epoch: 2 [6400/70668 (9%)]	Loss: 8475.077148
Train Epoch: 2 [9600/70668 (14%)]	Loss: 8174.880371
Train Epoch: 2 [12800/70668 (18%)]	Loss: 8240.173828
Train Epoch: 2 [16000/70668 (23%)]	Loss: 8541.399414
Train Epoch: 2 [19200/70668 (27%)]	Loss: 8386.293945
Train Epoch: 2 [22400/70668 (32%)]	Loss: 8177.061523
Train Epoch: 2 [25600/70668 (36%)]	Loss: 8114.039062
Train Epoch: 2 [28800/70668 (41%)]	Loss: 8344.156250
Train Epoch: 2 [32000/70668 (45%)]	Loss: 8360.887695
Train Epoch: 2 [35200/70668 (50%)]	Loss: 8413.091797
Train Epoch: 2 [38400/70668 (54%)]	Loss: 8379.414062
Train Epoch: 2 [41600/70668 (59%)]	Loss: 8313.823242
Train Epoch: 2 [44800/70668 (63%)]	Loss: 8489.648438
Train Epoch: 2 [48000/70668 (68%)]	Loss: 8383.729492
Train Epoch: 2 [51200/70668 (72%)]	Loss: 8166.588867
Train Epoch: 2 [54400/70668 (77%)]	Loss: 8215.540039
Train Epoch: 2 [57600/70668 (81%)]	Loss: 8523.433594
Train Epoch: 2 [60800/70668 (86%)]	Loss: 8596.645508
Train Epoch: 2 [64000/70668 (91%)]	Loss: 8376.310547
Train Epoch: 2 [67200/70668 (95%)]	Loss: 8331.311523
Train Epoch: 2 [70400/70668 (100%)]	Loss: 8422.896484
====> Epoch: 2 Average loss: 8372.5218
====> Test set loss: 8364.5293 - VLB-VAE : 267589.2058
Train Epoch: 3 [0/70668 (0%)]	Loss: 8304.603516
Train Epoch: 3 [3200/70668 (5%)]	Loss: 8356.637695
Train Epoch: 3 [6400/70668 (9%)]	Loss: 8355.633789
Train Epoch: 3 [9600/70668 (14%)]	Loss: 8379.444336
Train Epoch: 3 [12800/70668 (18%)]	Loss: 8478.660156
Train Epoch: 3 [16000/70668 (23%)]	Loss: 8065.681641
Train Epoch: 3 [19200/70668 (27%)]	Loss: 8309.211914
Train Epoch: 3 [22400/70668 (32%)]	Loss: 8581.408203
Train Epoch: 3 [25600/70668 (36%)]	Loss: 8411.899414
Train Epoch: 3 [28800/70668 (41%)]	Loss: 8300.701172
Train Epoch: 3 [32000/70668 (45%)]	Loss: 8355.332031
Train Epoch: 3 [35200/70668 (50%)]	Loss: 8273.023438
Train Epoch: 3 [38400/70668 (54%)]	Loss: 8215.341797
Train Epoch: 3 [41600/70668 (59%)]	Loss: 8731.381836
Train Epoch: 3 [44800/70668 (63%)]	Loss: 8441.828125
Train Epoch: 3 [48000/70668 (68%)]	Loss: 8291.887695
Train Epoch: 3 [51200/70668 (72%)]	Loss: 8286.142578
Train Epoch: 3 [54400/70668 (77%)]	Loss: 8415.724609
Train Epoch: 3 [57600/70668 (81%)]	Loss: 8473.810547
Train Epoch: 3 [60800/70668 (86%)]	Loss: 8380.942383
Train Epoch: 3 [64000/70668 (91%)]	Loss: 8367.693359
Train Epoch: 3 [67200/70668 (95%)]	Loss: 8272.653320
Train Epoch: 3 [70400/70668 (100%)]	Loss: 8357.915039
====> Epoch: 3 Average loss: 8358.6882
====> Test set loss: 8359.0821 - VLB-VAE : 267414.9451
Train Epoch: 4 [0/70668 (0%)]	Loss: 8413.631836
Train Epoch: 4 [3200/70668 (5%)]	Loss: 8442.791992
Train Epoch: 4 [6400/70668 (9%)]	Loss: 8299.204102
Train Epoch: 4 [9600/70668 (14%)]	Loss: 8405.569336
Train Epoch: 4 [12800/70668 (18%)]	Loss: 8043.338867
Train Epoch: 4 [16000/70668 (23%)]	Loss: 8664.883789
Train Epoch: 4 [19200/70668 (27%)]	Loss: 8429.337891
Train Epoch: 4 [22400/70668 (32%)]	Loss: 8316.811523
Train Epoch: 4 [25600/70668 (36%)]	Loss: 8238.440430
Train Epoch: 4 [28800/70668 (41%)]	Loss: 8312.193359
Train Epoch: 4 [32000/70668 (45%)]	Loss: 8161.324707
Train Epoch: 4 [35200/70668 (50%)]	Loss: 7988.363770
Train Epoch: 4 [38400/70668 (54%)]	Loss: 8364.322266
Train Epoch: 4 [41600/70668 (59%)]	Loss: 8459.030273
Train Epoch: 4 [44800/70668 (63%)]	Loss: 8197.347656
Train Epoch: 4 [48000/70668 (68%)]	Loss: 8218.698242
Train Epoch: 4 [51200/70668 (72%)]	Loss: 8379.177734
Train Epoch: 4 [54400/70668 (77%)]	Loss: 8260.768555
Train Epoch: 4 [57600/70668 (81%)]	Loss: 8089.949707
Train Epoch: 4 [60800/70668 (86%)]	Loss: 8768.464844
Train Epoch: 4 [64000/70668 (91%)]	Loss: 8456.463867
Train Epoch: 4 [67200/70668 (95%)]	Loss: 8154.192383
Train Epoch: 4 [70400/70668 (100%)]	Loss: 8513.551758
====> Epoch: 4 Average loss: 8350.0128
====> Test set loss: 8349.2444 - VLB-VAE : 267100.2283
Train Epoch: 5 [0/70668 (0%)]	Loss: 8250.059570
Train Epoch: 5 [3200/70668 (5%)]	Loss: 8479.858398
Train Epoch: 5 [6400/70668 (9%)]	Loss: 8415.189453
Train Epoch: 5 [9600/70668 (14%)]	Loss: 8483.650391
Train Epoch: 5 [12800/70668 (18%)]	Loss: 8312.074219
Train Epoch: 5 [16000/70668 (23%)]	Loss: 8145.714844
Train Epoch: 5 [19200/70668 (27%)]	Loss: 8144.618164
Train Epoch: 5 [22400/70668 (32%)]	Loss: 8350.916992
Train Epoch: 5 [25600/70668 (36%)]	Loss: 8204.193359
Train Epoch: 5 [28800/70668 (41%)]	Loss: 8389.189453
Train Epoch: 5 [32000/70668 (45%)]	Loss: 8295.622070
Train Epoch: 5 [35200/70668 (50%)]	Loss: 8222.869141
Train Epoch: 5 [38400/70668 (54%)]	Loss: 8667.498047
Train Epoch: 5 [41600/70668 (59%)]	Loss: 8387.810547
Train Epoch: 5 [44800/70668 (63%)]	Loss: 8443.249023
Train Epoch: 5 [48000/70668 (68%)]	Loss: 8359.603516
Train Epoch: 5 [51200/70668 (72%)]	Loss: 8060.278320
Train Epoch: 5 [54400/70668 (77%)]	Loss: 8381.723633
Train Epoch: 5 [57600/70668 (81%)]	Loss: 8467.178711
Train Epoch: 5 [60800/70668 (86%)]	Loss: 8524.952148
Train Epoch: 5 [64000/70668 (91%)]	Loss: 8466.298828
Train Epoch: 5 [67200/70668 (95%)]	Loss: 8343.005859
Train Epoch: 5 [70400/70668 (100%)]	Loss: 8440.922852
====> Epoch: 5 Average loss: 8344.8949
====> Test set loss: 8348.4883 - VLB-VAE : 267076.0407
Train Epoch: 6 [0/70668 (0%)]	Loss: 8431.014648
Train Epoch: 6 [3200/70668 (5%)]	Loss: 7999.915039
Train Epoch: 6 [6400/70668 (9%)]	Loss: 8378.695312
Train Epoch: 6 [9600/70668 (14%)]	Loss: 8415.142578
Train Epoch: 6 [12800/70668 (18%)]	Loss: 8400.334961
Train Epoch: 6 [16000/70668 (23%)]	Loss: 8384.455078
Train Epoch: 6 [19200/70668 (27%)]	Loss: 8210.847656
Train Epoch: 6 [22400/70668 (32%)]	Loss: 8368.068359
Train Epoch: 6 [25600/70668 (36%)]	Loss: 8171.329590
Train Epoch: 6 [28800/70668 (41%)]	Loss: 8099.890137
Train Epoch: 6 [32000/70668 (45%)]	Loss: 8342.351562
Train Epoch: 6 [35200/70668 (50%)]	Loss: 8475.061523
Train Epoch: 6 [38400/70668 (54%)]	Loss: 8353.889648
Train Epoch: 6 [41600/70668 (59%)]	Loss: 8343.282227
Train Epoch: 6 [44800/70668 (63%)]	Loss: 8162.830078
Train Epoch: 6 [48000/70668 (68%)]	Loss: 8498.812500
Train Epoch: 6 [51200/70668 (72%)]	Loss: 8430.725586
Train Epoch: 6 [54400/70668 (77%)]	Loss: 8561.181641
Train Epoch: 6 [57600/70668 (81%)]	Loss: 8612.803711
Train Epoch: 6 [60800/70668 (86%)]	Loss: 8286.711914
Train Epoch: 6 [64000/70668 (91%)]	Loss: 8254.674805
Train Epoch: 6 [67200/70668 (95%)]	Loss: 8523.919922
Train Epoch: 6 [70400/70668 (100%)]	Loss: 8432.455078
====> Epoch: 6 Average loss: 8340.3644
====> Test set loss: 8340.1753 - VLB-VAE : 266810.0991
Train Epoch: 7 [0/70668 (0%)]	Loss: 8466.836914
Train Epoch: 7 [3200/70668 (5%)]	Loss: 8440.523438
Train Epoch: 7 [6400/70668 (9%)]	Loss: 8165.869141
Train Epoch: 7 [9600/70668 (14%)]	Loss: 8532.227539
Train Epoch: 7 [12800/70668 (18%)]	Loss: 7977.931152
Train Epoch: 7 [16000/70668 (23%)]	Loss: 8226.791016
Train Epoch: 7 [19200/70668 (27%)]	Loss: 8233.268555
Train Epoch: 7 [22400/70668 (32%)]	Loss: 8391.957031
Train Epoch: 7 [25600/70668 (36%)]	Loss: 8378.131836
Train Epoch: 7 [28800/70668 (41%)]	Loss: 8285.410156
Train Epoch: 7 [32000/70668 (45%)]	Loss: 8571.992188
Train Epoch: 7 [35200/70668 (50%)]	Loss: 8045.017090
Train Epoch: 7 [38400/70668 (54%)]	Loss: 8325.691406
Train Epoch: 7 [41600/70668 (59%)]	Loss: 8589.008789
Train Epoch: 7 [44800/70668 (63%)]	Loss: 8236.234375
Train Epoch: 7 [48000/70668 (68%)]	Loss: 8357.634766
Train Epoch: 7 [51200/70668 (72%)]	Loss: 8313.555664
Train Epoch: 7 [54400/70668 (77%)]	Loss: 8390.171875
Train Epoch: 7 [57600/70668 (81%)]	Loss: 8503.877930
Train Epoch: 7 [60800/70668 (86%)]	Loss: 8449.458008
Train Epoch: 7 [64000/70668 (91%)]	Loss: 8364.600586
Train Epoch: 7 [67200/70668 (95%)]	Loss: 8503.331055
Train Epoch: 7 [70400/70668 (100%)]	Loss: 8455.779297
====> Epoch: 7 Average loss: 8337.6157
====> Test set loss: 8343.9356 - VLB-VAE : 266930.3957
Train Epoch: 8 [0/70668 (0%)]	Loss: 8379.117188
Train Epoch: 8 [3200/70668 (5%)]	Loss: 8453.709961
Train Epoch: 8 [6400/70668 (9%)]	Loss: 8276.812500
Train Epoch: 8 [9600/70668 (14%)]	Loss: 8360.049805
Train Epoch: 8 [12800/70668 (18%)]	Loss: 8390.251953
Train Epoch: 8 [16000/70668 (23%)]	Loss: 8331.669922
Train Epoch: 8 [19200/70668 (27%)]	Loss: 8172.160645
Train Epoch: 8 [22400/70668 (32%)]	Loss: 8298.473633
Train Epoch: 8 [25600/70668 (36%)]	Loss: 8411.888672
Train Epoch: 8 [28800/70668 (41%)]	Loss: 8440.190430
Train Epoch: 8 [32000/70668 (45%)]	Loss: 8160.944824
Train Epoch: 8 [35200/70668 (50%)]	Loss: 8240.741211
Train Epoch: 8 [38400/70668 (54%)]	Loss: 8432.226562
Train Epoch: 8 [41600/70668 (59%)]	Loss: 8563.802734
Train Epoch: 8 [44800/70668 (63%)]	Loss: 8421.411133
Train Epoch: 8 [48000/70668 (68%)]	Loss: 8178.392578
Train Epoch: 8 [51200/70668 (72%)]	Loss: 8287.862305
Train Epoch: 8 [54400/70668 (77%)]	Loss: 8401.363281
Train Epoch: 8 [57600/70668 (81%)]	Loss: 8340.365234
Train Epoch: 8 [60800/70668 (86%)]	Loss: 8283.120117
Train Epoch: 8 [64000/70668 (91%)]	Loss: 8364.612305
Train Epoch: 8 [67200/70668 (95%)]	Loss: 8002.431152
Train Epoch: 8 [70400/70668 (100%)]	Loss: 8208.269531
====> Epoch: 8 Average loss: 8335.3683
====> Test set loss: 8337.7158 - VLB-VAE : 266731.4156
Train Epoch: 9 [0/70668 (0%)]	Loss: 7958.628418
Train Epoch: 9 [3200/70668 (5%)]	Loss: 8238.008789
Train Epoch: 9 [6400/70668 (9%)]	Loss: 8392.575195
Train Epoch: 9 [9600/70668 (14%)]	Loss: 8305.657227
Train Epoch: 9 [12800/70668 (18%)]	Loss: 8184.978027
Train Epoch: 9 [16000/70668 (23%)]	Loss: 8287.496094
Train Epoch: 9 [19200/70668 (27%)]	Loss: 8007.484375
Train Epoch: 9 [22400/70668 (32%)]	Loss: 8301.998047
Train Epoch: 9 [25600/70668 (36%)]	Loss: 8472.488281
Train Epoch: 9 [28800/70668 (41%)]	Loss: 8489.418945
Train Epoch: 9 [32000/70668 (45%)]	Loss: 8319.933594
Train Epoch: 9 [35200/70668 (50%)]	Loss: 8269.333984
Train Epoch: 9 [38400/70668 (54%)]	Loss: 8335.813477
Train Epoch: 9 [41600/70668 (59%)]	Loss: 8365.665039
Train Epoch: 9 [44800/70668 (63%)]	Loss: 8357.671875
Train Epoch: 9 [48000/70668 (68%)]	Loss: 8328.649414
Train Epoch: 9 [51200/70668 (72%)]	Loss: 8218.500000
Train Epoch: 9 [54400/70668 (77%)]	Loss: 8041.638184
Train Epoch: 9 [57600/70668 (81%)]	Loss: 8288.270508
Train Epoch: 9 [60800/70668 (86%)]	Loss: 8234.233398
Train Epoch: 9 [64000/70668 (91%)]	Loss: 8255.956055
Train Epoch: 9 [67200/70668 (95%)]	Loss: 8046.052246
Train Epoch: 9 [70400/70668 (100%)]	Loss: 8032.385254
====> Epoch: 9 Average loss: 8334.2203
====> Test set loss: 8336.8157 - VLB-VAE : 266702.6221
